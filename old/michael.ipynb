{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Particle: # all the material that is relavant at the level of the individual particles\n",
    "    \n",
    "    def __init__(self, xx, yy, dim, minx, maxx):\n",
    "        self.position = np.random.uniform(low=minx, high=maxx, size=dim)\n",
    "        self.velocity = np.random.uniform(low=-0.1, high=0.1, size=dim)\n",
    "    \n",
    "        self.best_particle_pos = self.position\n",
    "        self.dim = dim\n",
    "        \n",
    "        self.xx = xx\n",
    "        self.yy = yy\n",
    "        \n",
    "        self.fitness = loss_function(self.xx, self.position, self.yy)\n",
    "        \n",
    "        self.best_particle_fitness = self.fitness   # we couldd start with very large number here, \n",
    "                                                    #but the actual value is better in case we are lucky \n",
    "                \n",
    "    def setPos(self, pos):\n",
    "        self.position = pos\n",
    "        self.fitness = loss_function(self.xx, self.position, self.yy)\n",
    "        if self.fitness<self.best_particle_fitness:     # to update the personal best both \n",
    "                                                        # position (for velocity update) and\n",
    "                                                        # fitness (the new standard) are needed\n",
    "                                                        # global best is update on swarm leven\n",
    "            self.best_particle_fitness = self.fitness\n",
    "            self.best_particle_pos = pos\n",
    "\n",
    "    def updateVel(self, inertia, a1, a2, best_self_pos, best_swarm_pos):\n",
    "                # Here we use the canonical version\n",
    "                # V <- inertia*V + a1r1 (peronal_best - current_pos) + a2r2 (global_best - current_pos)\n",
    "        cur_vel = self.velocity\n",
    "        r1 = np.random.uniform(low=0, high=1, size = self.dim)\n",
    "        r2 = np.random.uniform(low=0, high=1, size = self.dim)\n",
    "        a1r1 = np.multiply(a1, r1)\n",
    "        a2r2 = np.multiply(a2, r2)\n",
    "        best_self_dif = np.subtract(best_self_pos, self.position)\n",
    "        best_swarm_dif = np.subtract(best_swarm_pos, self.position)\n",
    "                    # the next line is the main equation, namely the velocity update, \n",
    "                    # the velocities are added to the positions at swarm level \n",
    "        return inertia*cur_vel + np.multiply(a1r1, best_self_dif) + np.multiply(a2r2, best_swarm_dif)\n",
    "\n",
    "    \n",
    "class PSO: # all the material that is relavant at swarm leveel\n",
    "\n",
    "    def __init__(self, xx, yy, w, a1, a2, dim, population_size, time_steps, search_range):\n",
    "\n",
    "        # Here we use values that are (somewhat) known to be good\n",
    "        # There are no \"best\" parameters (No Free Lunch), so try using different ones\n",
    "        # There are several papers online which discuss various different tunings of a1 and a2\n",
    "        # for different types of problems\n",
    "        self.xx = xx\n",
    "        self.yy = yy\n",
    "        self.w = w # Inertia\n",
    "        self.a1 = a2 # Attraction to personal best\n",
    "        self.a2 = a2 # Attraction to global best\n",
    "        self.dim = dim\n",
    "        \n",
    "        print(search_range)\n",
    "        self.swarm = [Particle(self.xx, self.yy, dim, -search_range, search_range) for i in range(population_size)]\n",
    "        self.time_steps = time_steps\n",
    "        print('init')\n",
    "\n",
    "        # Initialising global best, you can wait until the end of the first time step\n",
    "        # but creating a random initial best and fitness which is very high will mean you\n",
    "        # do not have to write an if statement for the one off case\n",
    "        self.best_swarm_pos = np.random.uniform(low=-500, high=500, size=dim)\n",
    "        self.best_swarm_fitness = 1e100\n",
    "        \n",
    "\n",
    "    def run(self):\n",
    "        for t in range(self.time_steps):\n",
    "            for p in range(len(self.swarm)):\n",
    "                particle = self.swarm[p]\n",
    "\n",
    "                new_position = particle.position + particle.updateVel(self.w, self.a1, self.a2, particle.best_particle_pos, self.best_swarm_pos)\n",
    "                                \n",
    "                if new_position@new_position > 1.0e+18: # The search will be terminated if the distance \n",
    "                                                        # of any particle from center is too large\n",
    "                    print('Time:', t,'Best Pos:',self.best_swarm_pos,'Best Fit:',self.best_swarm_fitness)\n",
    "                    raise SystemExit('Most likely divergent: Decrease parameter values')\n",
    " \n",
    "                self.swarm[p].setPos(new_position)\n",
    "\n",
    "                new_fitness = loss_function(self.xx, new_position, self.yy)\n",
    "                if new_fitness < self.best_swarm_fitness:   # to update the global best both \n",
    "                                                            # position (for velocity update) and\n",
    "                    self.best_swarm_fitness = new_fitness\n",
    "                    self.best_swarm_pos = new_position\n",
    "\n",
    "            if t % 100 == 0: #we print only two components even it search space is high-dimensional\n",
    "                print(\"Time: %6d,  Best Fitness: %14.6f,  Best Pos: %9.4f,%9.4f,%9.4f\" % (t,self.best_swarm_fitness,self.best_swarm_pos[0],self.best_swarm_pos[1],self.best_swarm_pos[2]), end =\" \")\n",
    "                if self.dim>2: \n",
    "                    print('...')\n",
    "                else:\n",
    "                    print('')\n",
    "            return self.best_swarm_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(ww, xx):\n",
    "    yy = 1/(1+np.exp(-np.dot(ww,xx.T)))[:, None]\n",
    "    for i in range(len(yy)):\n",
    "        if yy[i] >= 0.5:\n",
    "            yy[i] = 1\n",
    "        else:\n",
    "            yy[i] = -1\n",
    "    return yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(xx, ww, dd):\n",
    "    return np.sum(np.abs(dd-perceptron(ww, xx)))/len(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "init\n",
      "Time:      0,  Best Fitness:       0.040000,  Best Pos:  989.8405,  -3.3739,-218.2319 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-0eca97857f94>:2: RuntimeWarning: overflow encountered in exp\n",
      "  yy = 1/(1+np.exp(-np.dot(ww,xx.T)))[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time:    100,  Best Fitness:       0.000000,  Best Pos: 3053.2767, 377.7107,-907.0785 ...\n",
      "Time:    200,  Best Fitness:       0.000000,  Best Pos: 3053.2767, 377.7107,-907.0785 ...\n",
      "Time:    300,  Best Fitness:       0.000000,  Best Pos: 3053.2767, 377.7107,-907.0785 ...\n",
      "Time: 373 Best Pos: [3053.27673275  377.71066283 -907.07850719] Best Fit: 0.0\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "Most likely divergent: Decrease parameter values",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m Most likely divergent: Decrease parameter values\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xx1 = np.random.multivariate_normal(mean=[2,2], cov=[[1,0],[0,1]], size = 100)\n",
    "yy1 = np.ones(shape=(xx1.shape[0], 1))\n",
    "xx0 = np.random.multivariate_normal(mean=[-2,-2], cov=[[1,0],[0,1]], size = 100)\n",
    "yy0 = -np.ones(shape=(xx0.shape[0], 1))\n",
    "xx = np.vstack([xx1, xx0])\n",
    "yy = np.vstack([yy1, yy0])\n",
    "\n",
    "xx = np.hstack([xx, np.ones(shape=(xx.shape[0], 1))])\n",
    "\n",
    "ww = PSO(xx, yy, dim=3, w=0.7, a1=2.02, a2=2.02, population_size=30, time_steps=1000, search_range=1).run()\n",
    "\n",
    "ax, fig = plt.subplots()\n",
    "\n",
    "def function(x, ):\n",
    "    return (322/-165)*x +29/-165\n",
    "\n",
    "x_S = [x/10 for x in range(-45,45)]\n",
    "\n",
    "y = [function(x) for x in x_S]\n",
    "\n",
    "fig.scatter(xx[:,0][:,None],xx[:,1][:,None],c=yy)\n",
    "fig.plot(x_S,y,c='r',linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natcomp",
   "language": "python",
   "name": "natcomp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
